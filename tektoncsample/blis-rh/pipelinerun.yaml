apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  name: blis-rh-run
spec:
  timeouts:
    pipeline: 6h        # overall PipelineRun
    tasks: 5h30m          # per-task timeout
  taskRunTemplate:
    serviceAccountName: helm-installer
  workspaces:
    - name: data
      persistentVolumeClaim:
        claimName: data-pvc
    - name: target-credentials
      secret:
        secretName: s3-secret
        items:
          - key: AWS_ACCESS_KEY_ID
            path: AWS_ACCESS_KEY_ID
          - key: AWS_SECRET_ACCESS_KEY
            path: AWS_SECRET_ACCESS_KEY

  pipelineRef:
    name: blis-rh-train
  params:
    - { name: experimentId, value: "Dec2-blis-rh" }
    - { name: namespace, value: toslali }
    - { name: num_iter, value: 2000 }
    - name: stack
      value:
        variations: 
          - LLM_NAME: ibm-granite/granite-3.1-8b-instruct
            TP: 1
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: ibm-granite/granite-3.1-8b-instruct
            TP: 2
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: ibm-granite/granite-3.1-8b-instruct
            TP: 4
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: ibm-granite/granite-3.1-8b-instruct
            TP: 1
            GPU: A100-80
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: ibm-granite/granite-3.1-8b-instruct
            TP: 2
            GPU: A100-80
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: meta-llama/llama-3.1-8b-instruct
            TP: 1
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: meta-llama/llama-3.1-8b-instruct
            TP: 2
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: meta-llama/llama-3.1-8b-instruct
            TP: 4
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: meta-llama/llama-3.1-8b-instruct
            TP: 1
            GPU: A100-80
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: meta-llama/llama-3.1-8b-instruct
            TP: 2
            GPU: A100-80
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: meta-llama/llama-3.1-8b-instruct
            TP: 4
            GPU: A100-80
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: qwen/qwen2.5-7b-instruct
            TP: 1
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: qwen/qwen2.5-7b-instruct
            TP: 2
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: qwen/qwen2.5-7b-instruct
            TP: 4
            GPU: H100
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: qwen/qwen2.5-7b-instruct
            TP: 1
            GPU: A100-80
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: qwen/qwen2.5-7b-instruct
            TP: 2
            GPU: A100-80
            vllm_version: vllm/vllm-openai:v0.8.4
          - LLM_NAME: qwen/qwen2.5-7b-instruct
            TP: 4
            GPU: A100-80
            vllm_version: vllm/vllm-openai:v0.8.4

            
